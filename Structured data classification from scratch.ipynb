{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8056d039",
   "metadata": {},
   "source": [
    "# Structured data classification from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38060cf4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f82cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\safouane elh\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae729ae",
   "metadata": {},
   "source": [
    "### import all libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487e2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05359b80",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7fadb",
   "metadata": {},
   "source": [
    "###  download the data and load it into a Pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3fba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9f71e",
   "metadata": {},
   "source": [
    "### we use  shape to see the number of rows and columns of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d138455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92520ca",
   "metadata": {},
   "source": [
    "### here's a preview of a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832a3cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d8dd9",
   "metadata": {},
   "source": [
    "### spliting the data into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7908997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af7550",
   "metadata": {},
   "source": [
    "### generating a  tf.data.Dataset objects for each dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c34bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47f7dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=62>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=120>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=267>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=99>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=1.8>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'reversible'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfcc18",
   "metadata": {},
   "source": [
    "###  In this step we  batch the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e513742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c576b94",
   "metadata": {},
   "source": [
    "## Feature preprocessing with Keras layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad7878",
   "metadata": {},
   "source": [
    "### We will encode these features using one-hot encoding, For this example, we want a simple solution that will handle out of range inputs at inference, so we will use IntegerLookup()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e60fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff75473",
   "metadata": {},
   "source": [
    "## Build a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d5950",
   "metadata": {},
   "source": [
    "### With this done, we can create our end-to-end model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42205816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf7cf0",
   "metadata": {},
   "source": [
    "## Train the model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85cd7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 271ms/step - loss: 0.7167 - accuracy: 0.5413 - val_loss: 0.6571 - val_accuracy: 0.6066\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6557 - accuracy: 0.5950 - val_loss: 0.6038 - val_accuracy: 0.7049\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6206 - accuracy: 0.6364 - val_loss: 0.5573 - val_accuracy: 0.8197\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5875 - accuracy: 0.6942 - val_loss: 0.5191 - val_accuracy: 0.8197\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.7934 - val_loss: 0.4869 - val_accuracy: 0.8525\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.7273 - val_loss: 0.4626 - val_accuracy: 0.8197\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4891 - accuracy: 0.7479 - val_loss: 0.4430 - val_accuracy: 0.8197\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4764 - accuracy: 0.7769 - val_loss: 0.4277 - val_accuracy: 0.8033\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4489 - accuracy: 0.8223 - val_loss: 0.4152 - val_accuracy: 0.8033\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4724 - accuracy: 0.7851 - val_loss: 0.4057 - val_accuracy: 0.8033\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4336 - accuracy: 0.8017 - val_loss: 0.3983 - val_accuracy: 0.8033\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.7934 - val_loss: 0.3925 - val_accuracy: 0.8197\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4362 - accuracy: 0.7893 - val_loss: 0.3890 - val_accuracy: 0.8197\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.3864 - val_accuracy: 0.8197\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4007 - accuracy: 0.8099 - val_loss: 0.3850 - val_accuracy: 0.8197\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4153 - accuracy: 0.8058 - val_loss: 0.3826 - val_accuracy: 0.8197\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3938 - accuracy: 0.8140 - val_loss: 0.3804 - val_accuracy: 0.8197\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.8306 - val_loss: 0.3787 - val_accuracy: 0.8197\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3848 - accuracy: 0.7975 - val_loss: 0.3773 - val_accuracy: 0.8197\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3774 - accuracy: 0.8347 - val_loss: 0.3755 - val_accuracy: 0.8197\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3769 - accuracy: 0.8512 - val_loss: 0.3744 - val_accuracy: 0.8361\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3565 - accuracy: 0.8430 - val_loss: 0.3739 - val_accuracy: 0.8361\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3430 - accuracy: 0.8636 - val_loss: 0.3745 - val_accuracy: 0.8525\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3572 - accuracy: 0.8306 - val_loss: 0.3747 - val_accuracy: 0.8689\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8471 - val_loss: 0.3750 - val_accuracy: 0.8689\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3467 - accuracy: 0.8264 - val_loss: 0.3759 - val_accuracy: 0.8689\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3361 - accuracy: 0.8554 - val_loss: 0.3771 - val_accuracy: 0.8689\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8512 - val_loss: 0.3772 - val_accuracy: 0.8689\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3152 - accuracy: 0.8760 - val_loss: 0.3769 - val_accuracy: 0.8689\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3056 - accuracy: 0.8760 - val_loss: 0.3771 - val_accuracy: 0.8689\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8554 - val_loss: 0.3776 - val_accuracy: 0.8689\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8884 - val_loss: 0.3784 - val_accuracy: 0.8689\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3073 - accuracy: 0.8554 - val_loss: 0.3797 - val_accuracy: 0.8689\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.8595 - val_loss: 0.3788 - val_accuracy: 0.8689\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.8678 - val_loss: 0.3780 - val_accuracy: 0.8689\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8760 - val_loss: 0.3784 - val_accuracy: 0.8689\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3068 - accuracy: 0.8512 - val_loss: 0.3779 - val_accuracy: 0.8689\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2978 - accuracy: 0.8802 - val_loss: 0.3792 - val_accuracy: 0.8525\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 0.8636 - val_loss: 0.3794 - val_accuracy: 0.8525\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3109 - accuracy: 0.8636 - val_loss: 0.3796 - val_accuracy: 0.8525\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2933 - accuracy: 0.8719 - val_loss: 0.3789 - val_accuracy: 0.8525\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2923 - accuracy: 0.8678 - val_loss: 0.3788 - val_accuracy: 0.8525\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3111 - accuracy: 0.8678 - val_loss: 0.3784 - val_accuracy: 0.8361\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2911 - accuracy: 0.8843 - val_loss: 0.3797 - val_accuracy: 0.8525\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2861 - accuracy: 0.8760 - val_loss: 0.3804 - val_accuracy: 0.8525\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2905 - accuracy: 0.8843 - val_loss: 0.3825 - val_accuracy: 0.8525\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 0.8843 - val_loss: 0.3833 - val_accuracy: 0.8525\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3110 - accuracy: 0.8802 - val_loss: 0.3848 - val_accuracy: 0.8525\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2869 - accuracy: 0.8802 - val_loss: 0.3831 - val_accuracy: 0.8525\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3172 - accuracy: 0.8678 - val_loss: 0.3830 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291476292b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fcf47c",
   "metadata": {},
   "source": [
    "## Inference on new data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb566c53",
   "metadata": {},
   "source": [
    "###  To get a prediction for a new sample, you can simply call model.predict().  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "132cc0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 891ms/step\n",
      "This particular patient had a 29.0 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32abf4c",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "For the first step \"Preparing the data\" in this lab i learn how i can load our dataset into a pandas dataframe and how we can splinted into a training and validation set using 80% for the training and 20% for the validation with the define the input features and the target.¶\n",
    "In the second step “Feature preprocessing with Keras layers\" i see how we can use the Normalization () layer to make sure the mean of each feature is 0 and its standard deviation is 1, also i see how we can use the StringLookup to turn our string features into integer.\n",
    "for \"the build model\" step i pick up how we can encoded Categorical features as integers or string, with choosing the number of nodes in each hidden layer, also the best activation function, Optimizer algorithm (to minimize the cost function) and the Regularization technique (to prevent the overfitting problem) appropriate to augment the accuracy of our model.\n",
    "at the final “Inference on new data\" i discover how i can inference our model on new data with using the model.predict to get a prediction for a new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492201a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
